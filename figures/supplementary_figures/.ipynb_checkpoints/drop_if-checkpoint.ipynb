{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = anndata.read('data/kang_count.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway_ann_matrix = load_annotations(\n",
    "    'data/c2.cp.reactome.v7.4.symbols.gmt',\n",
    "    data.var_names,\n",
    "    min_genes=13\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['REACTOME_ANTIVIRAL_MECHANISM_BY_IFN_STIMULATED_GENES',\n",
       " 'REACTOME_DDX58_IFIH1_MEDIATED_INDUCTION_OF_INTERFERON_ALPHA_BETA',\n",
       " 'REACTOME_INTERFERON_GAMMA_SIGNALING',\n",
       " 'REACTOME_INTERFERON_ALPHA_BETA_SIGNALING',\n",
       " 'REACTOME_INTERFERON_SIGNALING']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in pathway_ann_matrix.columns if 'INTERFERON' in x or 'IFN' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pathways_list = [x for x in pathway_ann_matrix.columns if 'INTERFERON' in x or 'IFN' in x]\n",
    "drop_pathway_ann_matrix = pathway_ann_matrix.loc[:,~pathway_ann_matrix.columns.isin(true_pathways_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.varm['annotations'] = drop_pathway_ann_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REACTOME_CYTOKINE_SIGNALING_IN_IMMUNE_SYSTEM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ISG15</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIB2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRKCZ</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KCNAB2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTNNBIP1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CYP19A1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAP1GAP2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSTR2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIRC5</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLCB4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>979 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          REACTOME_CYTOKINE_SIGNALING_IN_IMMUNE_SYSTEM\n",
       "index                                                 \n",
       "ISG15                                             True\n",
       "MIB2                                             False\n",
       "PRKCZ                                            False\n",
       "KCNAB2                                           False\n",
       "CTNNBIP1                                         False\n",
       "...                                                ...\n",
       "CYP19A1                                          False\n",
       "RAP1GAP2                                         False\n",
       "SSTR2                                            False\n",
       "BIRC5                                             True\n",
       "PLCB4                                            False\n",
       "\n",
       "[979 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is looking for the column that 'IFITM3' is still a part of \n",
    "# drop_pathway_ann_matrix['REACTOME_CYTOKINE_SIGNALING_IN_IMMUNE_SYSTEM']['IFITM3']\n",
    "\n",
    "drop_pathway_ann_matrix.iloc[:,drop_pathway_ann_matrix.loc['IFITM3',:].values == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "membership_mask = data.varm['annotations'].astype(bool).T\n",
    "X_train, X_test = train_test_split(\n",
    "    data.X,\n",
    "    test_size=0.25,\n",
    "    shuffle=True,\n",
    "    random_state=0,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 979)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "membership_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import pmVAEModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one layer of 12 nodes --> 4 nodes per pathway\n",
    "kangVAE = pmVAEModel(\n",
    "    membership_mask.values,\n",
    "    [12],\n",
    "    4,\n",
    "    beta=1e-05,\n",
    "    terms=membership_mask.index,\n",
    "    add_auxiliary_module=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pmVAE(\n",
       "  (encoder_net): pmEncoder(\n",
       "    (encoder_dense_1): CustomizedLinear(input_features=979, output_features=2352, bias=True)\n",
       "    (encoder_norm_1): BatchNorm1d(2352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (encoder_elu_1): ELU(alpha=1.0, inplace=True)\n",
       "    (encoder_dense_2): CustomizedLinear(input_features=2352, output_features=1568, bias=True)\n",
       "    (encoder_norm_2): BatchNorm1d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (decoder_net): pmDecoder(\n",
       "    (decoder_dense_1): CustomizedLinear(input_features=784, output_features=2352, bias=True)\n",
       "    (decoder_norm_1): BatchNorm1d(2352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (decoder_elu_1): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (merge_layer): CustomizedLinear(input_features=2352, output_features=979, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kangVAE.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class RNASeqData(Dataset):\n",
    "    \n",
    "    def __init__(self, X, c=None, y=None, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.c = c\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.X[index,:]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        if self.y is not None and self.c is not None:\n",
    "            return sample, self.y[index], self.c[index]\n",
    "        if self.y is None and self.c is not None:\n",
    "            return sample, self.c[index]\n",
    "        else:\n",
    "            return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = RNASeqData(X_train)\n",
    "test_ds = RNASeqData(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Epoch 000 --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/aspiro17/pace_genome_bio/models.py:798: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample_weight = torch.tensor(sample_weight, dtype=y_pred.dtype).cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: training loss 063.1713,validation loss 086.6973\n",
      "-------- Epoch 001 --------\n",
      "Epoch 001: training loss 038.3499,validation loss 035.9961\n",
      "-------- Epoch 002 --------\n",
      "Epoch 002: training loss 032.6766,validation loss 030.1187\n",
      "-------- Epoch 003 --------\n",
      "Epoch 003: training loss 029.2131,validation loss 027.1577\n",
      "-------- Epoch 004 --------\n",
      "Epoch 004: training loss 026.4924,validation loss 024.6304\n",
      "-------- Epoch 005 --------\n",
      "Epoch 005: training loss 024.3599,validation loss 022.5730\n",
      "-------- Epoch 006 --------\n",
      "Epoch 006: training loss 022.5134,validation loss 021.0449\n",
      "-------- Epoch 007 --------\n",
      "Epoch 007: training loss 021.0564,validation loss 019.4743\n",
      "-------- Epoch 008 --------\n",
      "Epoch 008: training loss 019.6843,validation loss 018.3276\n",
      "-------- Epoch 009 --------\n",
      "Epoch 009: training loss 018.5813,validation loss 017.4884\n",
      "-------- Epoch 010 --------\n",
      "Epoch 010: training loss 017.5598,validation loss 016.2355\n",
      "-------- Epoch 011 --------\n",
      "Epoch 011: training loss 016.7750,validation loss 015.5898\n",
      "-------- Epoch 012 --------\n",
      "Epoch 012: training loss 015.9994,validation loss 014.8348\n",
      "-------- Epoch 013 --------\n",
      "Epoch 013: training loss 015.4091,validation loss 014.0985\n",
      "-------- Epoch 014 --------\n",
      "Epoch 014: training loss 014.7043,validation loss 013.6930\n",
      "-------- Epoch 015 --------\n",
      "Epoch 015: training loss 014.2245,validation loss 013.0555\n",
      "-------- Epoch 016 --------\n",
      "Epoch 016: training loss 013.6697,validation loss 012.7022\n",
      "-------- Epoch 017 --------\n",
      "Epoch 017: training loss 013.2552,validation loss 012.1726\n",
      "-------- Epoch 018 --------\n",
      "Epoch 018: training loss 012.8528,validation loss 011.7191\n",
      "-------- Epoch 019 --------\n",
      "Epoch 019: training loss 012.5193,validation loss 011.4027\n",
      "-------- Epoch 020 --------\n",
      "Epoch 020: training loss 012.0703,validation loss 011.0720\n",
      "-------- Epoch 021 --------\n",
      "Epoch 021: training loss 011.7476,validation loss 010.7846\n",
      "-------- Epoch 022 --------\n",
      "Epoch 022: training loss 011.5013,validation loss 010.4575\n",
      "-------- Epoch 023 --------\n",
      "Epoch 023: training loss 011.2956,validation loss 010.1896\n",
      "-------- Epoch 024 --------\n",
      "Epoch 024: training loss 010.9701,validation loss 010.0088\n",
      "-------- Epoch 025 --------\n",
      "Epoch 025: training loss 010.7104,validation loss 009.8165\n",
      "-------- Epoch 026 --------\n",
      "Epoch 026: training loss 010.4651,validation loss 009.4901\n",
      "-------- Epoch 027 --------\n",
      "Epoch 027: training loss 010.1882,validation loss 009.2810\n",
      "-------- Epoch 028 --------\n",
      "Epoch 028: training loss 010.0388,validation loss 009.0264\n",
      "-------- Epoch 029 --------\n",
      "Epoch 029: training loss 009.8879,validation loss 008.8679\n",
      "-------- Epoch 030 --------\n",
      "Epoch 030: training loss 009.6857,validation loss 008.6709\n",
      "-------- Epoch 031 --------\n",
      "Epoch 031: training loss 009.5237,validation loss 008.4904\n",
      "-------- Epoch 032 --------\n",
      "Epoch 032: training loss 009.3441,validation loss 008.3598\n",
      "-------- Epoch 033 --------\n",
      "Epoch 033: training loss 009.2144,validation loss 008.2191\n",
      "-------- Epoch 034 --------\n",
      "Epoch 034: training loss 009.1120,validation loss 008.0721\n",
      "-------- Epoch 035 --------\n",
      "Epoch 035: training loss 008.9662,validation loss 007.9536\n",
      "-------- Epoch 036 --------\n",
      "Epoch 036: training loss 008.7385,validation loss 007.7885\n",
      "-------- Epoch 037 --------\n",
      "Epoch 037: training loss 008.6192,validation loss 007.6371\n",
      "-------- Epoch 038 --------\n",
      "Epoch 038: training loss 008.5146,validation loss 007.5208\n",
      "-------- Epoch 039 --------\n",
      "Epoch 039: training loss 008.4214,validation loss 007.3790\n",
      "-------- Epoch 040 --------\n",
      "Epoch 040: training loss 008.1913,validation loss 007.2418\n",
      "-------- Epoch 041 --------\n",
      "Epoch 041: training loss 008.1139,validation loss 007.1071\n",
      "-------- Epoch 042 --------\n",
      "Epoch 042: training loss 007.9527,validation loss 007.0123\n",
      "-------- Epoch 043 --------\n",
      "Epoch 043: training loss 007.8521,validation loss 006.8791\n",
      "-------- Epoch 044 --------\n",
      "Epoch 044: training loss 007.7596,validation loss 006.8184\n",
      "-------- Epoch 045 --------\n",
      "Epoch 045: training loss 007.7023,validation loss 006.7045\n",
      "-------- Epoch 046 --------\n",
      "Epoch 046: training loss 007.5860,validation loss 006.6192\n",
      "-------- Epoch 047 --------\n",
      "Epoch 047: training loss 007.4381,validation loss 006.5626\n",
      "-------- Epoch 048 --------\n",
      "Epoch 048: training loss 007.5481,validation loss 006.5057\n",
      "-------- Epoch 049 --------\n",
      "Epoch 049: training loss 007.3453,validation loss 006.3587\n",
      "-------- Epoch 050 --------\n",
      "Epoch 050: training loss 007.2497,validation loss 006.3602\n",
      "-------- Epoch 051 --------\n",
      "Epoch 051: training loss 006.9443,validation loss 006.0690\n",
      "-------- Epoch 052 --------\n",
      "Epoch 052: training loss 006.9496,validation loss 006.0570\n",
      "-------- Epoch 053 --------\n",
      "Epoch 053: training loss 006.8586,validation loss 006.0273\n",
      "-------- Epoch 054 --------\n",
      "Epoch 054: training loss 006.8176,validation loss 006.0413\n",
      "-------- Epoch 055 --------\n",
      "Epoch 055: training loss 006.8654,validation loss 005.9847\n",
      "-------- Epoch 056 --------\n",
      "Epoch 056: training loss 006.8182,validation loss 005.9911\n",
      "-------- Epoch 057 --------\n",
      "Epoch 057: training loss 006.9075,validation loss 005.9921\n",
      "-------- Epoch 058 --------\n",
      "Epoch 058: training loss 006.8904,validation loss 006.0540\n",
      "-------- Epoch 059 --------\n",
      "Epoch 059: training loss 006.9206,validation loss 006.0218\n",
      "-------- Epoch 060 --------\n",
      "Epoch 060: training loss 006.8774,validation loss 005.9844\n",
      "-------- Epoch 061 --------\n",
      "Epoch 061: training loss 006.8640,validation loss 006.0127\n",
      "-------- Epoch 062 --------\n",
      "Epoch 062: training loss 006.8818,validation loss 005.9916\n",
      "-------- Epoch 063 --------\n",
      "Epoch 063: training loss 006.8327,validation loss 005.9826\n",
      "-------- Epoch 064 --------\n",
      "Epoch 064: training loss 006.8211,validation loss 005.9820\n",
      "-------- Epoch 065 --------\n",
      "Epoch 065: training loss 006.8251,validation loss 006.0433\n",
      "-------- Epoch 066 --------\n",
      "Epoch 066: training loss 006.8951,validation loss 006.0072\n",
      "-------- Epoch 067 --------\n",
      "Epoch 067: training loss 006.8605,validation loss 006.0521\n",
      "-------- Epoch 068 --------\n",
      "Epoch 068: training loss 006.8701,validation loss 005.9857\n",
      "-------- Epoch 069 --------\n",
      "Epoch 069: training loss 006.8461,validation loss 005.9843\n",
      "-------- Epoch 070 --------\n",
      "Epoch 070: training loss 006.8569,validation loss 006.0535\n",
      "-------- Epoch 071 --------\n",
      "Epoch 071: training loss 006.8683,validation loss 005.9943\n",
      "-------- Epoch 072 --------\n",
      "Epoch 072: training loss 006.7853,validation loss 006.0186\n",
      "-------- Epoch 073 --------\n",
      "Epoch 073: training loss 006.9421,validation loss 005.9917\n",
      "-------- Epoch 074 --------\n",
      "Epoch 074: training loss 006.8933,validation loss 006.0180\n",
      "-------- Epoch 075 --------\n",
      "Epoch 075: training loss 006.8723,validation loss 006.0821\n",
      "-------- Epoch 076 --------\n",
      "Epoch 076: training loss 006.8571,validation loss 005.9959\n",
      "-------- Epoch 077 --------\n",
      "Epoch 077: training loss 006.8611,validation loss 005.9879\n",
      "-------- Epoch 078 --------\n",
      "Epoch 078: training loss 006.8413,validation loss 006.0242\n",
      "-------- Epoch 079 --------\n",
      "Epoch 079: training loss 006.9787,validation loss 005.9661\n",
      "-------- Epoch 080 --------\n",
      "Epoch 080: training loss 006.8329,validation loss 006.0450\n",
      "-------- Epoch 081 --------\n",
      "Epoch 081: training loss 006.8166,validation loss 005.9965\n",
      "-------- Epoch 082 --------\n",
      "Epoch 082: training loss 006.8783,validation loss 006.0211\n",
      "-------- Epoch 083 --------\n",
      "Epoch 083: training loss 006.9092,validation loss 005.9875\n",
      "-------- Epoch 084 --------\n",
      "Epoch 084: training loss 006.9554,validation loss 006.0240\n",
      "-------- Epoch 085 --------\n",
      "Epoch 085: training loss 006.8305,validation loss 006.0252\n",
      "-------- Epoch 086 --------\n",
      "Epoch 086: training loss 006.8023,validation loss 005.9913\n",
      "-------- Epoch 087 --------\n",
      "Epoch 087: training loss 006.8729,validation loss 005.9791\n",
      "-------- Epoch 088 --------\n",
      "Epoch 088: training loss 006.9183,validation loss 005.9888\n",
      "-------- Epoch 089 --------\n",
      "Epoch 089: training loss 006.9058,validation loss 005.9862\n",
      "-------- Epoch 090 --------\n",
      "Epoch 090: training loss 006.8044,validation loss 005.9845\n",
      "-------- Epoch 091 --------\n",
      "Epoch 091: training loss 006.8616,validation loss 005.9896\n",
      "-------- Epoch 092 --------\n",
      "Epoch 092: training loss 006.8442,validation loss 005.9852\n",
      "-------- Epoch 093 --------\n",
      "Epoch 093: training loss 006.8647,validation loss 005.9944\n",
      "-------- Epoch 094 --------\n",
      "Epoch 094: training loss 006.8271,validation loss 005.9823\n",
      "-------- Epoch 095 --------\n",
      "Epoch 095: training loss 006.9519,validation loss 006.0097\n",
      "-------- Epoch 096 --------\n",
      "Epoch 096: training loss 006.9087,validation loss 005.9625\n",
      "-------- Epoch 097 --------\n",
      "Epoch 097: training loss 006.7985,validation loss 005.9776\n",
      "-------- Epoch 098 --------\n",
      "Epoch 098: training loss 006.8711,validation loss 005.9740\n",
      "-------- Epoch 099 --------\n",
      "Epoch 099: training loss 006.8599,validation loss 006.0059\n",
      "-------- Epoch 100 --------\n",
      "Epoch 100: training loss 006.7800,validation loss 005.9817\n",
      "-------- Epoch 101 --------\n",
      "Epoch 101: training loss 006.8663,validation loss 006.0037\n",
      "-------- Epoch 102 --------\n",
      "Epoch 102: training loss 006.9154,validation loss 006.0073\n",
      "-------- Epoch 103 --------\n",
      "Epoch 103: training loss 006.8636,validation loss 006.0002\n",
      "-------- Epoch 104 --------\n",
      "Epoch 104: training loss 006.8645,validation loss 006.0062\n",
      "-------- Epoch 105 --------\n",
      "Epoch 105: training loss 006.8248,validation loss 005.9901\n",
      "-------- Epoch 106 --------\n",
      "Epoch 106: training loss 006.9036,validation loss 006.0030\n",
      "-------- Epoch 107 --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7fd6d3e05940>\n",
      "Traceback (most recent call last):\n",
      "  File \"/homes/gws/aspiro17/miniconda3/envs/newenv/lib/python3.9/logging/__init__.py\", line 227, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 46501) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/newenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/newenv/lib/python3.9/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    113\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21691/1788732568.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkangVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pmvae_dropIFN_checkpoint.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/pace_genome_bio/models.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, max_epochs, lr, beta, batch_size, pathway_dropout, logpath, checkpoint_path, verbose)\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0mtrainloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathway_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpathway_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_c\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0mtrainloss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m             \u001b[0mvalloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_val_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_c\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0mvalloss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pace_genome_bio/models.py\u001b[0m in \u001b[0;36m_val_epoch\u001b[0;34m(self, val_dataloader, use_c)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_c\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/newenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/newenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/newenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/newenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 46501) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "#kangVAE.train(train_ds, test_ds, checkpoint_path='pmvae_dropIFN_checkpoint.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explain aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kangVAE.load_checkpoint('saved_models/pmvae_dropIFN_checkpoint.pkl.best_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "kangVAE.set_gpu(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_latent_wrapper(x):\n",
    "    outs = kangVAE.model(x)\n",
    "    z = outs.mu\n",
    "    return z[:,-4].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kangVAE.latent_space_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AUXILIARY-0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kangVAE.latent_space_names()[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AUXILIARY-1'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kangVAE.latent_space_names()[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AUXILIARY-2'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kangVAE.latent_space_names()[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AUXILIARY-3'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kangVAE.latent_space_names()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathexplainer import PathExplainerTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.tensor(data.X)\n",
    "input_data.requires_grad = True\n",
    "baseline_data = torch.zeros(data.X.shape[1])\n",
    "baseline_data.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = PathExplainerTorch(model_latent_wrapper)\n",
    "attributions = explainer.attributions(input_data,\n",
    "                                      baseline=baseline_data,\n",
    "                                      num_samples=200,\n",
    "                                      use_expectation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_attribs = attributions.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = pd.DataFrame(index=membership_mask.columns)\n",
    "top['means'] = np.abs(np_attribs).mean(0)\n",
    "top['stds'] = np.abs(np_attribs).std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>means</th>\n",
       "      <th>stds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IFITM3</th>\n",
       "      <td>0.709573</td>\n",
       "      <td>0.281454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OAS1</th>\n",
       "      <td>0.438794</td>\n",
       "      <td>0.252445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLA2G7</th>\n",
       "      <td>0.418400</td>\n",
       "      <td>0.296648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSB</th>\n",
       "      <td>0.353585</td>\n",
       "      <td>0.184553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISG20</th>\n",
       "      <td>0.333086</td>\n",
       "      <td>0.180179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLS2</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JAM2</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDO1</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARD9</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABCC2</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>979 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           means      stds\n",
       "index                     \n",
       "IFITM3  0.709573  0.281454\n",
       "OAS1    0.438794  0.252445\n",
       "PLA2G7  0.418400  0.296648\n",
       "SSB     0.353585  0.184553\n",
       "ISG20   0.333086  0.180179\n",
       "...          ...       ...\n",
       "GLS2    0.000013  0.000579\n",
       "JAM2    0.000012  0.000479\n",
       "CDO1    0.000011  0.000147\n",
       "CARD9   0.000009  0.000132\n",
       "ABCC2   0.000006  0.000192\n",
       "\n",
       "[979 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top.sort_values('means',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top.to_csv('kang_remove_if/aux_0.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
